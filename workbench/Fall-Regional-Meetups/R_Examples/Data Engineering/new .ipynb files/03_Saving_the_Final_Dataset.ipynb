{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Final Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the transformed and enriched dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "load(\"02_Transforming_and_Enriching_Data.RData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(df, \"../../data/output/customer_churn_abt.csv\", row.names = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Google Cloud Storage (if applicable)\n",
    "If we had GCS and wanted to save a table in it as a Parquet data set, we would use the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘arrow’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:utils’:\n",
      "\n",
      "    timestamp\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(arrow)\n",
    "library(googleCloudStorageR)\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "\n",
    "# Your Google service account JSON key\n",
    "gcs_key <- \"../../keys/gel-sas1-writer 1.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your GCS bucket and destination path\n",
    "bucket_name <- \"sas1-learn\"\n",
    "output_filename <- \"customer_churn_abt.parquet\"\n",
    "gcs_object_path <- paste0(\"data/\", output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in init_oauth_service_account(self$secrets, scope = self$params$scope, : Bad Request (HTTP 400).\n",
     "output_type": "error",
     "traceback": [
      "Error in init_oauth_service_account(self$secrets, scope = self$params$scope, : Bad Request (HTTP 400).\nTraceback:\n",
      "1. gar_auth_service(json_file = json_file)",
      "2. credentials_service_account(scopes = scope, path = json_file)",
      "3. httr::oauth_service_token(endpoint = gargle_oauth_endpoint(), \n .     secrets = info, scope = scopes, sub = subject)",
      "4. TokenServiceAccount$new(endpoint = endpoint, secrets = secrets, \n .     params = list(scope = scope, sub = sub))",
      "5. initialize(...)",
      "6. self$refresh()",
      "7. init_oauth_service_account(self$secrets, scope = self$params$scope, \n .     sub = self$params$sub)",
      "8. stop_for_status(res)",
      "9. stop(http_condition(x, \"error\", task = task, call = call))"
     ]
    }
   ],
   "source": [
    "# Authenticate with GCS\n",
    "Sys.setenv(GOOGLE_APPLICATION_CREDENTIALS = gcs_key)\n",
    "gcs_auth(json_file = gcs_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EXPORT ---\n",
    "\n",
    "# Save DataFrame as local Parquet file\n",
    "local_path <- tempfile(fileext = \".parquet\")\n",
    "write_parquet(df, local_path)\n",
    "\n",
    "# Upload to GCS\n",
    "gcs_upload(file = local_path,\n",
    "           bucket = bucket_name,\n",
    "           name = gcs_object_path,\n",
    "           predefinedAcl = 'bucketLevel')\n",
    " \n",
    "cat(sprintf(\"DataFrame written to %s\\n\", gcs_object_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Snowflake (if applicable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had Snowflake and wanted to save a table in it, we would do the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by loading the **reticulate** package whick allows users to run Python code, import Python modules, and pass data between R and Python directly within the same R notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(reticulate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can connect to Snowflake, we need to install the pandas-compatible version of the Snowflake Connector for Python onto the python version used by the reticulate package. First, copy the python path from the first line of output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open a terminal window and run the following line:\n",
    "\n",
    "<python path from py_config()> -m pip install \"snowflake-connector-python[pandas]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python modules\n",
    "\n",
    "json <- import(\"json\")\n",
    "sf_connector <- import(\"snowflake.connector\")\n",
    "sf_tools <- import(\"snowflake.connector.pandas_tools\")\n",
    "\n",
    "# Load Snowflake credentials from JSON\n",
    "sf_credential <- \"../../keys/snowflake_cred.json\"\n",
    "open <- import_builtins()$open\n",
    "f <- open(sf_credential, \"r\")\n",
    "sf_credentials_dict <- json$load(f)\n",
    "f$close()\n",
    "\n",
    "# Connect to Snowflake\n",
    "conn <- do.call(sf_connector$connect, sf_credentials_dict)\n",
    "\n",
    "# Convert R dataframe to Pandas dataframe\n",
    "pandas <- import(\"pandas\")\n",
    "df_pandas <- r_to_py(df)\n",
    "\n",
    "# Export to Snowflake\n",
    "result <- sf_tools$write_pandas(\n",
    "  conn = conn,\n",
    "  df = df_pandas,\n",
    "  table_name = \"customer_churn_abt\",\n",
    "  auto_create_table = TRUE,\n",
    "  overwrite = TRUE\n",
    ")\n",
    "\n",
    "# Close connection\n",
    "conn$close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
